<!DOCTYPE html>
<html>
<head>
<link rel="stylesheet" type="text/css" href="sst_review_style.css">
<title>3.5.3 Comparisons of Reconstructions </title>
</head>
<body>
<div class="row">
  <div class="column side">
  <p></p>
  </div>
  <div class="column middle">
<p><a href="3.5.2.html">Previous - 3.5.2 Other Structural Choices</a> <a href="index.html">Index</a> <a href="3.5.4.html">Next - 3.5.4 Summary of Reconstruction Techniques and Structural Uncertainty</a></p>
<h1>3.5.3 Comparisons of Reconstructions </h1>
<p>
Yasunaka and Hanawa [2011] examined a range of climate indices based on seven 
different SST data sets. They found that the disagreement between data sets was 
marked before 1880, and that the trends in large scale averages and indices tend 
to diverge outside of the common climatology period. For the global average, the 
differences between analyses were around 0.2 K before 1920 and around 0.1-0.2 K in 
the modern period. Even for relatively well-observed events such as the 1925/26 El 
Ni&ntilde;o, the detailed evolution of the SSTs in the tropical Pacific varied from 
analysis to analysis. The reasons for the discrepancies are not completely clear 
because each data set is based on a slightly different set of observations that have 
been quality controlled and processed in different ways, a problem that could be 
alleviated by running analyses on identical input data sets. 
</p><p>
Combined with information about large-scale sampling uncertainties estimated in other ways, the spread between analyses suggests that the large-scale sampling uncertainty in global average SST anomaly is around 0.2 K in the late 19th century. For the large-scale sampling uncertainty of the global average to be much larger would require variability in the early record to have been different from variability in the modern period, which is a possibility. The resolution of such a question is most likely to be achieved via the digitisation of more observations from paper records.
</p><p>
Progress in assessing the differences between analysis techniques can also be made by 
studying the relative strengths and weaknesses of interpolation techniques on carefully 
prepared test data sets using synthetic data, or on withheld data from well observed 
regions. By running each analysis on the same carefully-defined subsets and tests, it 
should be possible to isolate reasons for the differences between the analyses and 
assess the reliability of analysis uncertainty estimates. The 
<a href="http://www.surfacetemperatures.org/">International Surface 
Temperature Initiative</a> has been working on such 
benchmarking exercises for land surface air temperature data, building on work such as 
the COST ACTION project [Venema et al., 2012].
</p>
<p><a href="3.5.2.html">Previous - 3.5.2 Other Structural Choices</a> <a href="index.html">Index</a> <a href="3.5.4.html">Next - 3.5.4 Summary of Reconstruction Techniques and Structural Uncertainty</a></p>
<br><br><br><br>
</div>
</div>
</body>
</html>
